from datetime import timezone
from crawlers.naver_news import NaverNewsCrawler
from services.article_service import process_article
from repositories.keyword_repository import get_keywords
from repositories.state_repository import (
    get_last_crawled_at,
    update_last_crawled_at
)


def run_crawler():
    print("ğŸš€ í¬ë¡¤ë§ ì‹œì‘")

    crawler = NaverNewsCrawler()
    keywords = get_keywords()

    last_crawled_at = get_last_crawled_at()
    print(f"ğŸ“Œ ì´ì „ ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œê°„: {last_crawled_at}")

    newest_article_time = None

    for kw in keywords:
        keyword = kw["keyword"]
        print(f"ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰: {keyword}")

        articles = crawler.fetch_articles(keyword)

        for article in articles:

            article_time = article["published_at"]

            # timezone ì œê±°
            if article_time.tzinfo:
                article_time = (
                    article_time
                    .astimezone(timezone.utc)
                    .replace(tzinfo=None)
                )

            # ì´ì „ì— ìˆ˜ì§‘í•œ ê¸°ì‚¬ë©´ skip
            if last_crawled_at and article_time <= last_crawled_at:
                continue

            saved = process_article(article)

            if saved:
                print(f"âœ… ì €ì¥ ì™„ë£Œ: {saved['title']}")

                # ìµœì‹  ê¸°ì‚¬ ì‹œê°„ ê¸°ë¡
                if newest_article_time is None or article_time > newest_article_time:
                    newest_article_time = article_time

    if newest_article_time:
        print(f"ğŸ•’ ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œê°„ ì—…ë°ì´íŠ¸: {newest_article_time}")
        update_last_crawled_at(newest_article_time)

    print("âœ… í¬ë¡¤ë§ ì¢…ë£Œ")